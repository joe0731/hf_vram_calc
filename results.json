{
  "model": {
    "name": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "architecture": "llama4_text",
    "parameters": 107769861120,
    "parameters_formatted": "108B",
    "original_torch_dtype": "torch.bfloat16",
    "user_specified_dtype": "FP8"
  },
  "memory_requirements": [
    {
      "dtype": "FP8",
      "batch_size": 4,
      "sequence_length": 4096,
      "lora_rank": 16,
      "model_size_gib": 100.37,
      "kv_cache_size_gib": 1.5,
      "inference_total_gib": 120.44,
      "training_gib": 521.92,
      "lora_size_gib": 122.46
    }
  ]
}